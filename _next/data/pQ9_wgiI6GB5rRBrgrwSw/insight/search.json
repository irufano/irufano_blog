{"pageProps":{"posts":[{"slug":"build_basic_chatbot","meta":{"title":"Build a Basic Chatbot","date":"2025-01-13","description":"LangGraph` is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. ","author":"irufano","tags":["AI","Generative AI","Langgraph","Langchain"],"image":"https://langchain-ai.github.io/langgraph/static/wordmark_dark.svg"},"rawContent":"\n## AI Chatbot with langgraph\nThe world of AI is currently hyped, have you ever thought about creating your own AI chatbot? In this tutorial, we will make one using langgraph.\n\n\n## What is Langgraph\n`LangGraph` is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures, differentiating it from DAG-based solutions. As a very low-level framework, it provides fine-grained control over both the flow and state of your application, crucial for creating reliable agents. Additionally, LangGraph includes built-in persistence, enabling advanced human-in-the-loop and memory features.\n\nWe'll first create a simple chatbot using LangGraph. This chatbot will respond directly to user messages. Though simple, it will illustrate the core concepts of building with LangGraph. By the end of this section, you will have a built rudimentary chatbot.\n\nStart by creating a StateGraph. A StateGraph object defines the structure of our chatbot as a \"state machine\". We'll add nodes to represent the llm and functions our chatbot can call and edges to specify how the bot should transition between these functions.\n\n## Required Package\n```sh\npip install -U langgraph langchain_openai tavily-python dotenv\n```\n\n## Setup Environment\n```python\nimport os\n\nfrom dotenv import load_dotenv\n\nenv_file = os.getenv(\"ENV_FILE\", \".env\")  # Default to .env if ENV_FILE is not set\nload_dotenv(env_file)\n\n\ndef _set_env(var: str):\n    os.environ[var] = os.getenv(var, \"None\")\n    print(f\"{var} set!\")\n\n\n_set_env(\"OPENAI_API_KEY\")\n```\n\n## Create a Basic Chatbot\n### Create StateGraph\nStart by creating a StateGraph. A StateGraph object defines the structure of our chatbot as a \"state machine\". We'll add nodes to represent the llm and functions our chatbot can call and edges to specify how the bot should transition between these functions.\n\n```python\nfrom typing import Annotated\n\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.graph.message import add_messages\n\n\nclass State(TypedDict):\n    # Messages have the type \"list\". The `add_messages` function\n    # in the annotation defines how this state key should be updated\n    # (in this case, it appends messages to the list, rather than overwriting them)\n    messages: Annotated[list, add_messages]\n\n\ngraph_builder = StateGraph(State)\n```\nOur graph can now handle two key tasks:\n\n1. Each `node` can receive the current `State` as input and output an update to the state.\n2. Updates to `messages` will be appended to the existing list rather than overwriting it, thanks to the prebuilt `add_messages` function used with the Annotated syntax.\n\n### Add Node\nNext, add a \"`chatbot`\" node. Nodes represent units of work. They are typically regular python functions.\n\n```python\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\n\n\ndef chatbot(state: State):\n    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n\n\n# The first argument is the unique node name\n# The second argument is the function or object that will be called whenever\n# the node is used.\ngraph_builder.add_node(\"chatbot\", chatbot)\n```\n> [info]:\n>\n> How the chatbot node function takes the current State as input and returns a dictionary containing an updated messages list under the key \"messages\". This is the basic pattern for all LangGraph node functions.\n\nThe `add_messages` function in our `State` will append the llm's response messages to whatever messages are already in the state.\n\n### Add Edge\nNext, add an entry point. This tells our graph where to start its work each time we run it.\n\n```python\ngraph_builder.add_edge(START, \"chatbot\")\n```\n\nSimilarly, set a `finish` point. This instructs the graph \"**any time this node is run, you can exit.**\"\n\n```python\ngraph_builder.add_edge(\"chatbot\", END)\n```\n\n### Compile graph\n\nFinally, we'll want to be able to run our graph. To do so, call \"`compile()`\" on the graph builder. This creates a \"`CompiledGraph`\" we can use invoke on our state.\n\n```python\ngraph = graph_builder.compile()\n```\n\n### Visualize Graph (Optional)\n\nYou can visualize the graph using the `get_graph` method and one of the \"draw\" methods, like `draw_ascii` or `draw_png`. The `draw` methods each require additional dependencies.\n\n```python\nfrom IPython.display import Image, display\n\ntry:\n    display(Image(graph.get_graph().draw_mermaid_png()))\nexcept Exception:\n    # This requires some extra dependencies and is optional\n    pass\n```\noutput:\n![image](data:image/jpg;base64,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)\n\n\n### Run The Chatbot\nNow let's run the chatbot!\n\n> [tip]:\n>\n> You can exit the chat loop at any time by typing \"`quit`\", \"`exit`\", or \"`q`\".\n\n```python\ndef stream_graph_updates(user_input: str):\n    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n        for value in event.values():\n            print(\"Assistant:\", value[\"messages\"][-1].content)\n\n\nwhile True:\n    try:\n        user_input = input(\"User: \")\n        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n            print(\"Goodbye!\")\n            break\n\n        stream_graph_updates(user_input)\n    except:\n        # fallback if input() is not available\n        user_input = \"Hallo beri aku informasi mengenai langgraph?\"\n        print(\"User: \" + user_input)\n        stream_graph_updates(user_input)\n        break\n```\n\n**Congratulations!** You've built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a LangSmith Trace for the call above at the provided link.","readingTime":"4 min read"},{"slug":"git-cheatsheets","meta":{"title":"Git Cheatsheet","date":"2024-11-01","description":"Git cheatsheet commonly used daily","author":"irufano","tags":["Git","Cheatheets"],"image":"https://git-scm.com/images/logos/2color-lightbg@2x.png"},"rawContent":"\n## List commit\n```sh\ngit log -n [number] \n\n# or use --oneline for simple logs\ngit log -n [number] --oneline\n```\n\n## Rebase\n\n```sh\ngit rebase [branch base]\n\n# rebase n commit from head\ngit rebase -i HEAD~n\n\n\n# rebase the root of commit (the first commit)\ngit rebase -i --root\n```\n\n## Cherry-pick\n\n```sh\ngit cherry-pick [commit-hash]\n\n# or multi commit\ngit cherry-pick [commit-hash] [commit-hash] [commit-hash] \n```\n\n## Stash\n\n```sh\ngit stash\n\n# stash include untracked file\ngit stash --include-untracked\n\n# list stash\ngit stash list\n\n# pop stash\ngit stash pop stash@{n}\n\n# apply stash but keep stash log\ngit stash apply stash@{n)\n\n# remove specific stash\ngit stash drop stash@{n}\n```\n\n## Rename Branch\n### local\n```sh\ngit branch -m <new_name>\n# or\ngit branch -m <old_name> <new_name>\n```\n### remote\n```sh\ngit branch -m <new_name>\n# or\ngit branch -m <old_name> <new_name>\n\n# Then push the <new_name> local branch and reset the upstream branch\ngit push origin -u <new_name>\n\n# Then delete the <old_name> remote branch and finish!\ngit push origin --delete <old_name>\n```\n\n## Tag\n```sh\n# add tag local\ntag -a [TAGE_NAME] -m \"[TAGE_MESSAGE]\"\n\n# push tag to remote\ngit push origin [TAGE_NAME]\n\n# remove tag local\ngit tag -d [TAGE_NAME]\n\n# remove tag remote\ngit push -d origin [TAGE_NAME]\n\n# To get the most recent tag\ngit describe --tags --abbrev=0\n\n# To get the most recent tag, with the number of additional commits on top of the tagged object & more\ngit describe --tags \n\n# To get the most recent annotated tag\ngit describe --abbrev=0\n\n```\n\n## Edit last commit date\n```sh\ngit commit --amend --no-edit --date \"12/30/2024 10:19:19 +0700\" \n```","readingTime":"2 min read"},{"slug":"gen-ai-concepts","meta":{"title":"Generative AI Key Concepts","date":"2024-09-24","description":"Machine learning is a subset of AI that involves developing algorithms that allow computers to learn from & make predictions or decisions based on data.","author":"irufano","tags":["AI","Generative AI"],"image":"https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/01-introduction-to-genai/images/AI-diagram.png"},"rawContent":"\n## Definition\n\nGenerative AI refers to a type of artificial intelligence that creates new content, such as images, text, audio, or even video, based on patterns and data it has learned. What makes it a fantastic technology is that it democratizes AI, anyone can use it with as little as a text prompt, a sentence written in a natural language. There's no need for you to learn a language like Java or SQL to accomplish something worthwhile, all you need is to use your language, state what you want and out comes a suggestion from an AI model. The applications and impact for this is huge, you write or understand reports, write applications and much more, all in seconds.\n\nAfter decades of research in the AI field, a new model architecture – called Transformer – overcame the limits of RNNs, being able to get much longer sequences of text as input. Transformers are based on the attention mechanism, enabling the model to give different weights to the inputs it receives, ‘paying more attention’ where the most relevant information is concentrated, regardless of their order in the text sequence.\n\nMost of the recent generative AI models – also known as Large Language Models (LLMs), since they work with textual inputs and outputs – are indeed based on this architecture. What’s interesting about these models – trained on a huge amount of unlabeled data from diverse sources like books, articles and websites – is that they can be adapted to a wide variety of tasks and generate grammatically correct text with a semblance of creativity. So, not only did they incredibly enhance the capacity of a machine to ‘understand’ an input text, but they enabled their capacity to generate an original response in human language.\n\n## How do large language models work?\n\n### Tokenization\n\nLarge Language Models receive a text as input and generate a text as output. However, being statistical models, they work much better with numbers than text sequences. That’s why every input to the model is processed by a tokenizer, before being used by the core model. A token is a chunk of text – consisting of a variable number of characters, so the tokenizer's main task is splitting the input into an array of tokens. Then, each token is mapped with a token index, which is the integer encoding of the original text chunk.\n\n![image](https://github.com/irufano/generative-ai-for-beginners/raw/main/01-introduction-to-genai/images/tokenizer-example.png?WT.mc_id=academic-105485-koreyst)\n\n### Predicting output tokens\n\nGiven n tokens as input (with max n varying from one model to another), the model is able to predict one token as output. This token is then incorporated into the input of the next iteration, in an expanding window pattern, enabling a better user experience of getting one (or multiple) sentence as an answer. This explains why, if you ever played with ChatGPT, you might have noticed that sometimes it looks like it stops in the middle of a sentence.\n\n### Selection process\n\nThe output token is chosen by the model according to its probability of occurring after the current text sequence. This is because the model predicts a probability distribution over all possible ‘next tokens’, calculated based on its training. However, not always the token with the highest probability is chosen from the resulting distribution. A degree of randomness is added to this choice, in a way that the model acts in a non-deterministic fashion - we do not get the exact same output for the same input. This degree of randomness is added to simulate the process of creative thinking and it can be tuned using a model parameter called temperature.\n\n## Custom Knowledge Base\n\nTo add a knowledge base to an OpenAI-powered chatbot or application, you can use a variety of approaches depending on how dynamic and structured you want your knowledge base to be. Here are some common methods:\n\n###  Embedding Knowledge with Fine-Tuning\n- **Fine-tuning**: You can fine-tune the OpenAI model on your specific knowledge base or domain. This involves training the model on a custom dataset (such as product information, FAQs, internal documents) to improve its responses.\n  - Steps:\n    - Collect data (e.g., text documents, structured data).\n    - Format it into the proper input-output pairs (prompts and completions).\n    - Fine-tune the model using OpenAI's fine-tuning API.\n- **Use case**: Best for cases where knowledge is mostly static and doesn’t change often.\n\n### Use Knowledge Base API and Dynamic Retrieval\n\n- **External APIs**: Integrate the chatbot with a real-time knowledge base, such as a MySQL database, content management system, or external API.\n  - **Method**: Implement a retrieval mechanism that allows the chatbot to fetch answers from your dynamic database based on user queries. For instance, using vector embeddings to match user queries with the most relevant content in the database.\n  - **Tools**: You can use libraries like langchain to facilitate this process, creating a pipeline that pulls data dynamically based on user input.\n- **Use case**: Useful when your knowledge base is large, changes frequently, or needs to handle complex queries.\n\n### Contextual Knowledge with Prompts\n\n- **Long prompts with context**: You can inject specific information about your knowledge base directly into the prompt as context.\n  - **Method**: Before each query, construct a detailed prompt that includes relevant information from your knowledge base, which the model will use to provide context-aware answers.\n  - **Use case**: Best for handling small sets of information or specific queries where the information needed is known beforehand.\n\n### Augmenting with Vector Databases (e.g., Pinecone, FAISS)\n\n- **Vector search**: Store your knowledge base as embeddings in a vector database (like Pinecone, Weaviate, or FAISS). When a user asks a question, convert it to a vector, search for the most relevant knowledge entry, and use the result as part of the answer.\n  - **Method**: Convert text to embeddings using OpenAI or other models, and retrieve the most similar data points in response to a user query.\n  - **Use case:** Perfect for large datasets where similarity search is required to find relevant answers.\n\n### Hybrid Approach with LangChain and FastAPI\n\n- LangChain: LangChain enables building large language model (LLM) applications that can dynamically interact with databases and external systems. It helps set up a chatbot that can fetch data from knowledge bases like databases, APIs, and even web pages.\n  - Steps:\n    1. Store Knowledge: Define a knowledge base, which could be a SQL database, document store, or API.\n    2. Query Execution: Use an LLM with the LangChain framework to query the knowledge base dynamically.\n    3. FastAPI Integration: Combine this with FastAPI for serving the chatbot with dynamic knowledge retrieval.\n\n### Document Retrieval with Plugins or Middleware\n\n- OpenAI Plugins: If you're using OpenAI in an application, consider building or using a plugin or middleware that acts as a bridge to your knowledge base. For example, retrieving documents, querying databases, or even triggering workflows (e.g., customer support tickets) based on the query.\n- Use case: Ideal for more complex enterprise solutions, where OpenAI can function alongside existing systems.\n\n### Hybrid QA Pipelines (LLM + Traditional Search)\n\n- **Combining LLMs with traditional search**: You can combine the capabilities of language models with traditional search mechanisms like Elasticsearch or other keyword-based systems.\n  - **Method**: First, use search engines to retrieve relevant documents, and then pass those documents to OpenAI for processing and summarization.\n  - **Use case**: Works well in applications where quick retrieval from a large corpus of documents is needed, and then those documents are summarized or clarified by the LLM.","readingTime":"7 min read"},{"slug":"machine-learning-concepts","meta":{"title":"Machine Learning Key Concepts","date":"2024-09-17","description":"Machine learning is a subset of AI that involves developing algorithms that allow computers to learn from & make predictions or decisions based on data.","author":"irufano","tags":["Machine Learning"],"image":"https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/_images/plot_ML_flow_chart_12.png"},"rawContent":"\n## Definition\n\nMachine learning (ML) is a subset of artificial intelligence (AI) that involves developing algorithms that allow computers to learn from and make predictions or decisions `based on data`. Instead of being explicitly programmed to perform tasks, machine learning models `identify patterns` in data and improve their performance as they are exposed to more data over time.\n\n## Traditional Programming VS ML\n\n### Traditional Programming\n\nTraditional programming is a manual process—meaning a person (programmer) creates the program. But without anyone programming the logic, one has to manually formulate or code rules.\n\n> [note]: **Traditional Programming**\n> INPUT + PROGRAM = OUTPUT\n\n### Machine Learning\nIn machine learning, on the other hand, the algorithm automatically formulates the rules from the data.\n\n> [note]: **Machine Learning**\n> INPUT + OUTPUT = PROGRAM (Model)\n\n## Rules for Using ML\n\nThere are 3 rules that are needed when we are going to use machine learning. One is mandatory and the other 2 are optional.\n\n### Data\n\nData is mandatory rule. When we use machine learning, ensure we have `data`, specially `historical data` because machine learning is learned from experience, where one of the experiences is historical data. Once we have data we can probably use machine learning.\n\n### Pattern (Optional)\n\nWe must know that the problems we face have a `pattern`. One form of machine learning is pattern recognition. Once we know that the problem has pattern we can probably use machine learning, but if the problem has random stuff is can be hard to use machine learning.\n\n### The problem cannot be derived mathematically (Optional)\n\nWhen we use machine learning it is better the problem `can't be derived mathematically`. If the problem can be derived mathematically then actually the problem can be programmed explicitly, example determining odd-even numbers etc. But there are problem that have pattern and can't be derived mathematically, example disease detection, desease detection cannot be derived into mathematic formula.\n\n\n## Machine Learning Type\n\n### Supervised Learning\n\nIn supervised learning, the algorithm is trained on a dataset that contains both input features (data) and corresponding output labels (desired results). So in supervised learning requires `data` and `labels` as input. There are 2 types of supervised learning `Classification` and `Regression`.\n\nCharacteristics of Supervised Learning:\n\n1. **Labeled Data**: The training data includes input-output pairs. Each example in the dataset comes with a label or outcome. For example:     \n   - Input: Features like height, weight, and age.\n   - Output: A label like \"healthy\" or \"unhealthy\" for a health prediction model.\n\n2. **Goal**: The algorithm tries to minimize the difference between its predicted outputs and the actual outputs by finding the best mapping from inputs to outputs during training.\n\n3. **Training Process**: \n   - The model is fed with a labeled dataset (both input features and output labels).\n   - The model makes predictions and compares them to the actual labels.\n   - Based on this comparison, the model adjusts its internal parameters to improve accuracy.\n   - This process repeats until the model achieves satisfactory performance on the training data.\n\n#### Classification\n\n> [note]: F(X) => [0,1] \n> \n> *or*\n> \n> F(X) => [0,1,2,...]\n\n- The goal is to assign data points to predefined `categories` or `classes`.\n- **Binary Classification**: Two possible classes (e.g., spam vs. non-spam emails).\n- **Multi-class Classification**: More than two classes (e.g., classifying types of flowers into species).\n- **Examples**:\n  - Diagnosing diseases as “positive” or “negative”.\n  - Credit Scoring as \"accepted\" or \"rejected\"\n  - Classifying whether a customer will churn or stay.\n\n#### Regression\n\n> [note]: F(X) => R\n\n- The goal is to predict continuous values (`numerical outcomes`).\n- **Examples**:\n  - Predicting house prices based on features like size and location.\n  - Forecasting stock prices.\n  - Predicting the temperature at a specific location.\n\n#### Supervised learning model pipeline\n\n![Supervised learning models](https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/_images/plot_ML_flow_chart_12.png)\n<p class=\"text-sm\">Image by: <a class=\"no-underline\" href=\"https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/tutorial/text_analytics/general_concepts.html#supervised-learning-model-fit-x-y\">scikit-learn</a></p>\n\n### Unsupervised Learning\n\nUnsupervised learning is a type of machine learning where the model is trained on data that has no labeled outcomes. Unlike supervised learning, where the goal is to map inputs to specific labels, unsupervised learning focuses on uncovering the underlying structure or patterns within the data. The primary objective is to discover hidden relationships or groupings without human intervention or guidance.\nIncluded in unsupervised learning are clustering, Dimensionality Reduction etc.\n\nCharacteristic of Unsupervised Learning:\n1. **No Labels**: The data used in unsupervised learning is not labeled. The model works on its own to detect patterns, clusters, or associations without predefined categories or answers.\n2. **Exploratory**: It’s primarily used for data exploration to find patterns, groupings, or structures in the data.\n3. **Unstructured Data**: Often applied to unstructured or unlabeled datasets, such as customer purchase data, social media activity, or image datasets.\n\n#### Clustering\n\n- The goal is to `group data points` into clusters such that items in the same group are more similar to each other than to those in other groups.\n  \n- **Examples**: \n  - Grouping customers based on purchasing behavior to create customer segments for targeted marketing.\n  - Clustering desease\n\n#### Dimensionality Reduction\n\n- The goal is to `reduce the number of features` (or dimensions) in the data while retaining the most important information. This can help visualize high-dimensional data or improve the performance of machine learning models.\n\n- **Example**: Reducing the number of variables in a gene expression dataset from thousands to a smaller, more manageable set of features.\n  \n#### Association\n\n- The goal is to find `relationships between variables` in large datasets. It’s commonly used in market basket analysis to find items that frequently appear together in transactions.\n\n- **Example**: Identifying that customers who buy bread often buy butter as well.\n\n#### Anomaly Detection\n\n- The goal is to identify `outliers or unusual data points` that do not conform to the expected pattern. This can be critical in fields like fraud detection or predictive maintenance.\n\n- **Example**: Detecting fraudulent credit card transactions based on deviations from normal spending behavior.\n\n#### Unsupervised learning model pipeline\n\n![Unsupervised learning models](https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/_images/plot_ML_flow_chart_32.png)\n<p class=\"text-sm\">Image by: <a class=\"no-underline\" href=\"https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/tutorial/text_analytics/general_concepts.html#unsupervised-learning-model-fit-x\">scikit-learn</a></p>\n\n\n### Reinforcement Learning\n\nReinforcement Learning (RL) is a type of machine learning in which an agent learns to make decisions by interacting with an environment in order to `maximize a reward`. Unlike supervised or unsupervised learning, reinforcement learning does not rely on labeled datasets or direct supervision. Instead, the agent `learns through trial and error`, receiving feedback in the form of rewards or penalties for actions it takes.\n\nApplications of Reinforcement Learning:\n- **Game AI**: RL has been used to achieve superhuman performance in games like chess (AlphaZero), Go, and video games (e.g., Atari, Dota 2). Algorithms like Deep Q-Networks (DQN) and AlphaGo have demonstrated the power of RL in strategic decision-making.\n\n- **Robotics**: RL is widely used in robotics for tasks like navigation, manipulation, and locomotion, where robots learn to interact with the physical environment through trial and error.\n\n- **Autonomous Vehicles**: Self-driving cars use reinforcement learning to make decisions about navigation, lane changing, and collision avoidance in dynamic, unpredictable environments.\n\n- **Healthcare**: RL\n\n#### The Reinforcement Learning Process\n1. **Initialization**: The agent starts in an initial state and does not know how the environment works.\n\n2. **Action Selection**: The agent selects an action based on its current policy.\n\n3. **Transition**: The action changes the state of the environment.\n\n4. **Reward**: The agent receives feedback (a reward) from the environment.\n\n5. **Learning**: Based on the reward, the agent updates its knowledge (usually the value function or policy) to improve future actions.\n\n6. **Repeat**: The process continues, with the agent learning and adapting its strategy over time to maximize cumulative rewards.\n","readingTime":"7 min read"},{"slug":"post-docs","meta":{"title":"Insight Posts Documentation","date":"2024-09-15","description":"Documentation about insight post creation with markdown include meta data, section, paragraph etc.","author":"irufano","tags":["Markdown"]},"rawContent":"\nDocumentation about insight post creation with markdown. Use markdown for post, below the complete documentation:\n\n## Meta Data\n\nMeta data used in this post are `title`, `date`, `description`, `author` and `tags`. Title at this meta data used for title post. \n\n```js title=\"your-post.md\"\n---\ntitle: \"Your Post Title\"\ndate: \"2024-09-15\"\ndescription: \"Your post description\"\nauthor: \"author\"\ntags:\n  - your tag\n  - other tag\n---\n```\n\n## Paragraph\n\nTo create paragraph on post same like create paragraph as text.\n\n```md title=\"your-post.md\"\n<!-- first paragraph -->\nCommodo eu in adipisicing id eu elit nisi exercitation ipsum mollit cupidatat consequat non. Aute elit nulla sit ipsum pariatur do do esse culpa laboris. Officia est non reprehenderit adipisicing officia deserunt consectetur aute exercitation magna laboris ipsum ut. Veniam reprehenderit Lorem commodo et adipisicing dolor Lorem commodo do incididunt. Id tempor culpa laborum eiusmod est veniam. Officia fugiat mollit dolor adipisicing tempor voluptate proident qui.\n\n<!-- second paragraph -->\nLaboris nulla et amet fugiat. Sit amet ad quis in consequat esse incididunt velit est nulla. Irure exercitation excepteur eiusmod mollit ea aute ut qui exercitation aliquip ipsum cupidatat. Sint anim cillum velit magna aliqua officia eu eu reprehenderit tempor aliqua veniam dolore duis. Qui sunt mollit qui exercitation nulla in ullamco fugiat esse cupidatat officia. Eu ipsum enim velit tempor magna ea dolor sint Lorem.\n```\n\n## Image\n\nTo add image on post, you must put image on public directory, then access it on post with \n\n```md title=\"your-post.md\"\n![Alt text for the image](/yourpath_image.png)\n```\n\n## Section\n\nThe section will show on the right of the post. The section that will show only `##` and the `###`.\n\n```md title=\"your-post.md\"\n## Section 1\n\nEiusmod sint laborum nostrud aliquip excepteur reprehenderit id in aliqua.\n\n### Section 1.1\n\nNisi veniam et fugiat nostrud nulla incididunt ut eiusmod eiusmod ex velit sunt Lorem.\n\n## Section 2\n\nPariatur magna sit pariatur in sit ex quis nulla nostrud ipsum proident cillum et et.\n\n## Section 2.1\nExcepteur dolor dolor pariatur dolore exercitation.\n```\n\n## Bullet and Numbering\nTo create bullet and numbering you can use `-` or `^[0-9]+$` for numbering.\n\n```md title=\"your-post.md\"\n- bullet 1\n- bullet 2\n- bullet 3\n\n1. number 1\n2. number 2\n3. number 3\n```\n\n- bullet 1\n- bullet 2\n- bullet 3\n\n1. number 1\n2. number 2\n3. number 3\n\n## Emphasis \nTo create emphasis on post like *this is emphasis*. We can use `*` between word or sentence.\n\n```md title=\"your-post.md\"\n*This is emphasis*\n\n*Hello*\n\n*Good Morning*\n```\n\n## Strong\nTo create strong text on post like **this is strong**. We can use `**` between word or sentence.\n\n```md title=\"your-post.md\"\n**This is strong**\n\n**Hello**\n\n**Good Morning**\n```\n\n## Code\n### Inline Code\nTo create inline code on post like `this is inline code`. We can use **`** between word or sentence.\n\n```md title=\"your-post.md\"\n`This is inline code`\n\n`Hello`\n\n`Good Morning`\n```\n\n### Code Block\nTo create code block on post. Follow the example below:\n\n```markdown title=\"your-post.md\"\n'```js title=\"your-code-title.js\"\nfuntion getData () => {\n    console.log(\"Hello world!\");\n}\n```'\n\n<!-- remove ' -->\n```\n\n## Blockquote\n\n### Info\n\n```markdown title=\"your-post.md\"\n> [info]:\n>\n> this is info blockquote example\n```\noutput:\n\n> [info]:\n>\n> this is info blockquote example\n\n### Warning\n\n```markdown title=\"your-post.md\"\n> [warning]:\n>\n> this is warning blockquote example\n```\noutput:\n\n> [warning]:\n>\n> this is warning blockquote example\n\n### Tip\n\n```markdown title=\"your-post.md\"\n> [tip]:\n>\n> this is tip blockquote example\n```\noutput:\n\n> [tip]:\n>\n> this is tip blockquote example\n\n### Important\n\n```markdown title=\"your-post.md\"\n> [important]:\n>\n> this is important blockquote example\n```\noutput:\n\n> [important]:\n>\n> this is important blockquote example\n\n### caution\n\n```markdown title=\"your-post.md\"\n> [caution]:\n>\n> this is caution blockquote example\n```\noutput:\n\n> [caution]:\n>\n> this is caution blockquote example\n\n### Note\n\nNote block is doesn't have title header.\n\n```markdown title=\"your-post.md\"\n> [note]:\n>\n> this is note blockquote example\n```\noutput:\n\n> [note]: This is note *blockquote* `example`\n>\n> Cillum adipisicing sint cupidatat mollit duis.\n>\n> Tempor proident veniam est veniam minim minim consectetur cupidatat Lorem cupidatat adipisicing. Ea ipsum excepteur pariatur non cupidatat amet exercitation enim id fugiat officia nostrud. Velit laboris laboris qui labore dolore fugiat mollit in laborum labore Lorem.\n>\n>\n> ```js title=\"your-code-title.js\"\n> funtion getData () => {\n>    console.log(\"Hello world!\");\n> }\n> ```","readingTime":"4 min read"}]},"__N_SSG":true}